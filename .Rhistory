mutate(journal = str_to_lower(journal)) %>%
mutate(journal = str_trim(journal))
tab_relecture_articles <- ANX4$i_8_evaluation_articles %>%
clean_names() %>%
select(revue_ouvrage, nombre_de_relectures) %>%
mutate(revue_ouvrage = str_to_lower(revue_ouvrage)) %>%
mutate(revue_ouvrage = str_trim(revue_ouvrage)) %>%
full_join(articles, by = c("revue_ouvrage" = "journal")) %>%
arrange(revue_ouvrage) %>%
unique() %>%
group_by(revue_ouvrage) %>%
summarise(n_relecture = sum(nombre_de_relectures, na.rm = TRUE), n_publi = sum(n, na.rm = TRUE)) %>%
ungroup() %>%
unique()
# Chunk 14
tab_relecture_articles %>%
mutate(diff = abs(n_publi - n_relecture)) %>%
filter(diff > 1) %>%
ggplot(aes(x = reorder(revue_ouvrage, -n_publi))) +
geom_segment(aes(
x = reorder(revue_ouvrage, -n_publi), xend = reorder(revue_ouvrage, -n_publi),
y = n_publi, yend = n_relecture
)) +
geom_point(aes(y = n_publi, fill = "Nombre de publications"), color = "black", shape = 21, size = 4, alpha = 0.8) +
geom_point(aes(y = n_relecture, fill = "Nombre de relectures"), color = "black", shape = 21, size = 4, alpha = 0.8) +
theme_inrae() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
labs(x = "Revues", y = "Nombre", fill = "Type") +
scale_y_continuous(breaks = seq(0, 30, 2))
# Chunk 15
tab_relecture_articles %>%
mutate(diff = abs(n_publi - n_relecture)) %>%
filter(diff > 1) %>%
ggplot(aes(x = reorder(revue_ouvrage, -n_publi))) +
geom_hline(yintercept = 0, size = 2) +
geom_segment(aes(
x = reorder(revue_ouvrage, -n_publi), xend = reorder(revue_ouvrage, -n_publi),
y = n_publi, yend = -n_relecture
)) +
geom_point(aes(y = n_publi, fill = "Nombre de publications"), color = "black", shape = 21, size = 4, alpha = 0.8) +
geom_point(aes(y = -n_relecture, fill = "Nombre de relectures"), color = "black", shape = 21, size = 4, alpha = 0.8) +
theme_inrae() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
labs(x = "Revues", y = "Nombre", fill = "Type") +
scale_y_continuous(breaks = seq(-30, 12, 2))
# Chunk 16
table_auteurs <- readxl::read_excel("data/table_auteurs_ETBX_2020-07-27_SL_DC.xlsx") %>% clean_names()
liste_auteurs_etbx <- table_auteurs %>%
filter(etbx_oui_non %in% c("oui", "temporaire", "oui / BSA")) %>%
pull(auteur)
liste_auteurs_etbx
# Chunk 17
calcul_nb_copubli <- function(x) {
liste_auteurs_etbx[str_detect(x, liste_auteurs_etbx)] %>%
gsub("^\\.|\\.$", "", .) %>%
unique() %>%
length()
}
clean_revues <- function(x){
r <- case_when(x == "water research, elsevier" ~ "water research",
x == "water resources research, agu" ~ "water resources research",
x == "water science and technology: water supply, iwa" ~ "water science and technology: water supply",
x == "vertigo - la revue électronique en sciences de l'environnement 1" ~ "vertigo",
x == "revue internationale des etudes du développement" ~ "revue internationale des etudes du developpement",
x == "journal of hydroinformatics, iwa" ~ "journal of hydroinformatics",
x == TRUE ~ x)
if(is.na(r)){return(x)}
return(r)
}
# Top 5
ANX4$i_1_articles_sctfq %>%
clean_names() %>%
select(reference_complete) %>%
rowwise() %>%
mutate(nb_copubli = calcul_nb_copubli(reference_complete)) %>%
ungroup() %>%
arrange(desc(nb_copubli)) %>%
slice(1:5)
# Chunk 18
word_count <- ANX4$i_1_articles_sctfq %>%
clean_names() %>%
select(reference_complete, journal) %>%
rowwise() %>%
mutate(nb_copubli = calcul_nb_copubli(reference_complete)) %>%
ungroup() %>%
mutate(journal = clean_revues(journal)) %>%
group_by(journal) %>%
summarise(nb_moyen = mean(nb_copubli)) %>%
ungroup() %>%
arrange(desc(nb_moyen))
# wordcloud2(word_count, size = 0.35)
word_count
word_count$journal
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# Chunk 2: packages
library(dplyr)
library(tidyr)
library(lubridate)
library(janitor)
library(ggplot2)
library(readxl)
library(purrr)
library(bib2df)
library(wordcloud2)
library(stringr)
source("R/theme_inrae.R")
# Chunk 3
# Fichier en date du 27/07/2020
file <- "data/Annexe4_ETBX_complet_2020_07_27.xlsx"
# On réalise une boucle pour importer tous les onglets dans un seul objet, sous forme de liste
sheet_names <- readxl::excel_sheets(file)
ANX4 <- list()
for (i in sheet_names[-1:-3]) {
ANX4[[i]] <- readxl::read_excel(file, sheet = i, skip = 1) %>%
select(-1) # Retrait colonne n°
}
# On rend exploitables les noms d'onglets
names(ANX4) <- janitor::make_clean_names(names(ANX4))
# Chunk 4
replace_cases <- function(x) {
value <- ifelse(is.na(x), yes = 0, no = 1)
return(value)
}
# Chunk 5
tab_dim <- tibble(
Onglet = names(ANX4),
nb_lignes = map_dbl(ANX4, nrow),
nb_colonnes = map_dbl(ANX4, ncol)
) %>%
arrange(desc(nb_lignes))
# On ne va garder que les onglets qui ne sont pas vides.
# Les onglets à 2 lignes sont à chaque fois vide (car la colonne n° a été remplie pour 1 et 2)
# sauf pour 4 onglets particuliers qui sont ici rajoutés.
Onglets_non_empty <- tab_dim %>%
filter(nb_lignes != 2) %>%
pull(Onglet) %>%
c("ii_3_activ_consult", "iii_1_elearning", "i_9_contrats_internationaux", "i_1_articles_synth")
# On affiche le tableau (Seulement le top 10)
tab_dim %>%
filter(Onglet %in% Onglets_non_empty) %>%
slice(1:10)
# Chunk 6
## Extraction des projets nationaux
projets_nationaux <- ANX4$i_9_contrats_nationaux %>%
clean_names() %>%
select(-x11) %>%
drop_na(contrat) %>%
drop_na(date_debut) %>%
mutate(type = "National")
## Projets européens
projets_europ <- ANX4$i_9_contrats_europ_autres %>%
drop_na(`Date début`) %>%
clean_names() %>%
mutate_at(vars(date_debut:date_fin), as.Date) %>%
mutate(type = "Européen")
## Projets internationaux
projets_inter <- ANX4$i_9_contrats_internationaux %>%
clean_names() %>%
mutate_at(vars(date_debut:date_fin), as.Date) %>%
mutate(type = "International")
## Projets R&D
projets_rd <- ANX4$i_9_contrats_prive_r_d_indus %>%
clean_names() %>%
mutate_at(vars(date_debut:date_fin), as.Date) %>%
mutate(type = "R&D")
## Projets PIA
projets_pia <- ANX4$i_9_contrats_pia %>%
clean_names() %>%
drop_na(contrat, date_debut) %>%
mutate_at(vars(date_debut:date_fin), as.Date) %>%
mutate(type = "PIA")
## Projets de collectivités territoriales
projets_coll_terri <- ANX4$i_9_contrats_coll_territ %>%
clean_names() %>%
drop_na(contrat, date_debut, date_fin) %>%
mutate_at(vars(date_debut), as.Date, origin = "1899-12-31") %>%
mutate(type = "National")
## On assemble le tout
PRJ <- bind_rows(projets_nationaux, projets_europ) %>%
bind_rows(projets_inter) %>%
bind_rows(projets_rd) %>%
bind_rows(projets_pia) %>%
bind_rows(projets_coll_terri) %>%
mutate_at(vars(porteur:axe_3), replace_cases) %>%
unique() %>%
mutate(date_fin = replace_na(date_fin, "2024-01-01")) %>%
mutate(porteur = recode(porteur, "0" = "Non porteur", "1" = "Porteur")) %>%
mutate(porteur = factor(porteur, levels = c("Porteur", "Non porteur"))) %>%
group_by(contrat) %>%
summarise(
date_debut = min(date_debut),
date_fin = max(date_fin),
porteur = unique(porteur),
type = unique(type)
) %>%
ungroup() %>%
arrange(date_debut) %>%
mutate(contrat = factor(contrat, levels = unique(contrat)))
# Chunk 7
ggplot(PRJ, aes(x = date_fin, y = contrat)) +
geom_segment(aes(x = date_debut, xend = date_fin, y = contrat, yend = contrat, color = type, linetype = porteur), size = 1.5) +
scale_y_discrete(limits = rev(levels(PRJ$contrat))) +
geom_point(fill = "black", color = "black", size = 3) +
geom_point(aes(x = date_debut, y = contrat), color = "black", fill = "black", size = 3) +
theme_inrae() +
theme(axis.text.y = element_text(size = 10)) +
geom_vline(xintercept = as.Date("2020-06-01"), color = "blue", size = 4) +
labs(x = "Temps", y = "Contrats", color = "Type de contrat", linetype = "ETBX porteur ?")
# Chunk 8
PRJ %>%
mutate(
annee_debut = lubridate::year(date_debut),
annee_fin = lubridate::year(date_fin)
) %>%
group_by(annee_debut) %>%
count(type) %>%
spread(key = annee_debut, value = n) %>%
ungroup() %>%
mutate_at(vars(`2013`:`2019`), replace_na, 0)
# Chunk 9
PRJ %>%
mutate(
annee_debut = lubridate::year(date_debut),
annee_fin = lubridate::year(date_fin)
) %>%
group_by(annee_fin) %>%
count(type) %>%
spread(key = annee_fin, value = n) %>%
ungroup() %>%
mutate_at(vars(`2017`:`2025`), replace_na, 0)
# Chunk 10
par_an <- PRJ %>%
mutate(
annee_debut = lubridate::year(date_debut),
annee_fin = lubridate::year(date_fin)
)
l <- list()
for (i in 2014:2020) {
l[[as.character(i)]] <- par_an %>%
filter(annee_debut <= i & annee_fin >= i) %>%
mutate(an = i)
}
count_type <- function(df) {
df %>%
group_by(type, an) %>%
count() %>%
arrange(desc(n))
}
map(l, count_type) %>%
bind_rows() %>%
spread(key = an, value = n) %>%
ungroup() %>%
mutate_at(vars(`2014`:`2020`), replace_na, 0)
# Chunk 11
acl1 <- ANX4$i_1_articles_sctfq %>%
clean_names() %>%
mutate(year = stringr::str_extract(reference_complete, "\\d{4}")) %>%
drop_na(year) %>%
group_by(year) %>%
summarise(n = n_distinct(reference_complete)) %>%
spread(key = year, value = n) %>%
mutate(Type = "Articles")
acl2 <- ANX4$i_1_autres_articles %>%
clean_names() %>%
mutate(year = stringr::str_extract(reference_complete, "\\d{4}")) %>%
filter(year != 2016) %>%
drop_na(year) %>%
group_by(year) %>%
summarise(n = n_distinct(reference_complete)) %>%
spread(key = year, value = n) %>%
mutate(Type = "Autres articles")
acl3 <- ANX4$i_3_articles_actes_colloq %>%
clean_names() %>%
mutate(year = stringr::str_extract(reference_complete, "\\d{4}")) %>%
drop_na(year) %>%
group_by(year) %>%
summarise(n = n_distinct(reference_complete)) %>%
spread(key = year, value = n) %>%
mutate(Type = "Actes colloques")
acl4 <- ANX4$i_2_chap_ouvrages %>%
clean_names() %>%
mutate(year = stringr::str_extract(reference_complete, "\\d{4}")) %>%
drop_na(year) %>%
group_by(year) %>%
summarise(n = n_distinct(reference_complete)) %>%
spread(key = year, value = n) %>%
mutate(Type = "Chapitres ouvrages")
bind_rows(acl1, acl2, acl3, acl4) %>%
select(Type, `2017`:`2020`)
# Chunk 12
clean_revues <- function(x){
r <- case_when(x == "water research, elsevier" ~ "water research",
x == "water resources research, agu" ~ "water resources research",
x == "water science and technology: water supply, iwa" ~ "water science and technology: water supply",
x == "vertigo - la revue électronique en sciences de l'environnement 1" ~ "vertigo",
x == "revue internationale des etudes du développement" ~ "revue internationale des etudes du developpement",
x == "journal of hydroinformatics, iwa" ~ "journal of hydroinformatics",
x == TRUE ~ x)
if(is.na(r)){return(x)}
return(r)
}
word_count <- ANX4$i_1_articles_sctfq %>%
clean_names() %>%
mutate(journal = clean_revues(journal)) %>%
group_by(journal) %>%
count() %>%
arrange(desc(n)) %>%
ungroup() %>%
rowwise() %>%
mutate(n = ifelse(journal == "Journal of Water Resources Planning and Management", yes = 7, no = n)) %>%
mutate(journal = ifelse(journal == "Journal of Water Resources Planning and Management", yes = "Water Res. Planning and Management", no = journal)) %>%
ungroup() %>%
mutate(journal = str_to_lower(journal)) %>%
mutate(journal = str_trim(journal))
# wordcloud2(word_count, size = 0.35)
# Chunk 13
articles <- ANX4$i_1_articles_sctfq %>%
clean_names() %>%
mutate(journal = clean_revues(journal)) %>%
group_by(journal) %>%
count() %>%
arrange(desc(n)) %>%
mutate(journal = str_to_lower(journal)) %>%
mutate(journal = str_trim(journal))
tab_relecture_articles <- ANX4$i_8_evaluation_articles %>%
clean_names() %>%
select(revue_ouvrage, nombre_de_relectures) %>%
mutate(revue_ouvrage = str_to_lower(revue_ouvrage)) %>%
mutate(revue_ouvrage = str_trim(revue_ouvrage)) %>%
full_join(articles, by = c("revue_ouvrage" = "journal")) %>%
arrange(revue_ouvrage) %>%
unique() %>%
mutate(revue_ouvrage = clean_revues(revue_ouvrage)) %>%
group_by(revue_ouvrage) %>%
summarise(n_relecture = sum(nombre_de_relectures, na.rm = TRUE), n_publi = sum(n, na.rm = TRUE)) %>%
ungroup() %>%
unique()
# Chunk 14
tab_relecture_articles %>%
mutate(diff = abs(n_publi - n_relecture)) %>%
filter(diff > 1) %>%
ggplot(aes(x = reorder(revue_ouvrage, -n_publi))) +
geom_segment(aes(
x = reorder(revue_ouvrage, -n_publi), xend = reorder(revue_ouvrage, -n_publi),
y = n_publi, yend = n_relecture
)) +
geom_point(aes(y = n_publi, fill = "Nombre de publications"), color = "black", shape = 21, size = 4, alpha = 0.8) +
geom_point(aes(y = n_relecture, fill = "Nombre de relectures"), color = "black", shape = 21, size = 4, alpha = 0.8) +
theme_inrae() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
labs(x = "Revues", y = "Nombre", fill = "Type") +
scale_y_continuous(breaks = seq(0, 30, 2))
# Chunk 15
tab_relecture_articles %>%
mutate(diff = abs(n_publi - n_relecture)) %>%
filter(diff > 1) %>%
ggplot(aes(x = reorder(revue_ouvrage, -n_publi))) +
geom_hline(yintercept = 0, size = 2) +
geom_segment(aes(
x = reorder(revue_ouvrage, -n_publi), xend = reorder(revue_ouvrage, -n_publi),
y = n_publi, yend = -n_relecture
)) +
geom_point(aes(y = n_publi, fill = "Nombre de publications"), color = "black", shape = 21, size = 4, alpha = 0.8) +
geom_point(aes(y = -n_relecture, fill = "Nombre de relectures"), color = "black", shape = 21, size = 4, alpha = 0.8) +
theme_inrae() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
labs(x = "Revues", y = "Nombre", fill = "Type") +
scale_y_continuous(breaks = seq(-30, 12, 2))
# Chunk 16
table_auteurs <- readxl::read_excel("data/table_auteurs_ETBX_2020-07-27_SL_DC.xlsx") %>% clean_names()
liste_auteurs_etbx <- table_auteurs %>%
filter(etbx_oui_non %in% c("oui", "temporaire", "oui / BSA")) %>%
pull(auteur)
liste_auteurs_etbx
# Chunk 17
calcul_nb_copubli <- function(x) {
liste_auteurs_etbx[str_detect(x, liste_auteurs_etbx)] %>%
gsub("^\\.|\\.$", "", .) %>%
unique() %>%
length()
}
# Top 5
ANX4$i_1_articles_sctfq %>%
clean_names() %>%
select(reference_complete) %>%
rowwise() %>%
mutate(nb_copubli = calcul_nb_copubli(reference_complete)) %>%
ungroup() %>%
arrange(desc(nb_copubli)) %>%
slice(1:5)
# Chunk 18
word_count <- ANX4$i_1_articles_sctfq %>%
clean_names() %>%
select(reference_complete, journal) %>%
rowwise() %>%
mutate(nb_copubli = calcul_nb_copubli(reference_complete)) %>%
ungroup() %>%
mutate(journal = clean_revues(journal)) %>%
group_by(journal) %>%
summarise(nb_moyen = mean(nb_copubli)) %>%
ungroup() %>%
arrange(desc(nb_moyen))
# wordcloud2(word_count, size = 0.35)
# Chunk 19
table_disciplines <- table_auteurs %>%
filter(etbx_oui_non %in% c("oui", "temporaire", "oui / BSA")) %>%
select(auteur, discipline) %>%
drop_na()
calcul_discipline <- function(x) {
df <- data.frame(auteur = liste_auteurs_etbx[str_detect(x, liste_auteurs_etbx)] %>% gsub("^\\.|\\.$", "", .) %>% unique())
df %>%
inner_join(table_disciplines, by = "auteur") %>%
pull(discipline) %>%
unique() %>%
paste(collapse = " / ")
}
# Top 5
ANX4$i_1_articles_sctfq %>%
clean_names() %>%
select(reference_complete) %>%
rowwise() %>%
mutate(disciplines = calcul_discipline(reference_complete)) %>%
mutate(nb_disciplines = str_split(disciplines, " / ")[[1]] %>% length()) %>%
ungroup() %>%
arrange(desc(nb_disciplines)) %>%
slice(1:5)
# Chunk 20
mono_dis <- ANX4$i_1_articles_sctfq %>%
clean_names() %>%
select(reference_complete) %>%
rowwise() %>%
mutate(nb_copubli = calcul_nb_copubli(reference_complete)) %>%
mutate(disciplines = calcul_discipline(reference_complete)) %>%
mutate(nb_disciplines = str_split(disciplines, " / ")[[1]] %>% length()) %>%
filter(nb_copubli > 1 & nb_disciplines == 1)
# Chunk 21
solo <- ANX4$i_1_articles_sctfq %>%
clean_names() %>%
select(reference_complete) %>%
rowwise() %>%
mutate(nb_copubli = calcul_nb_copubli(reference_complete)) %>%
filter(nb_copubli == 1)
# Chunk 22
HAL <- jsonlite::fromJSON("data/ETBX_2017_2020.json")$response$docs %>% tibble()
HAL %>%
filter(docType_s %in% c("ART", "COUV")) %>%
rowwise() %>%
mutate(Acronymes = list(c(c_across(contains("Acronym"))))) %>%
mutate(Noms = list(c(c_across(contains("StructName"))))) %>%
mutate(Pays = list(c(c_across(contains("Country"))))) %>%
pull(Noms) %>%
unlist() %>%
unique() -> structures
HAL %>% count(docType_s)
liste_revues_jcr <- list()
for(i in list.files("data/revues")) {
nom = str_remove_all(i,".csv")
liste_revues_jcr[[nom]] <- read_csv(file.path("data/revues/",i), skip = 1) %>% tibble() %>%
janitor::clean_names() %>%
select(full_journal_title, total_cites, journal_impact_factor) %>%
mutate(total_cites = as.numeric(total_cites),
journal_impact_factor = as.numeric(journal_impact_factor))
}
table_jcr <- bind_rows(liste_revues_jcr) %>% mutate(full_journal_title = str_to_lower(full_journal_title)) %>% unique()
tab_relecture_articles$revue_ouvrage %in% table_jcr$full_journal_title %>% sum()
tab_relecture_articles$revue_ouvrage[
tab_relecture_articles$revue_ouvrage %in% table_jcr$full_journal_title]
tab_relecture_articles$revue_ouvrage[
tab_relecture_articles$revue_ouvrage %in% table_jcr$full_journal_title]
tab_relecture_articles %>% inner_join(table_jcr, by = c("revue_ouvrage"="full_journal_title"))
liste_revues_jcr <- list()
for(i in list.files("data/revues")) {
nom = str_remove_all(i,".csv")
liste_revues_jcr[[nom]] <- read_csv(file.path("data/revues/",i), skip = 1) %>% tibble() %>%
janitor::clean_names() %>%
select(full_journal_title, total_cites, journal_impact_factor) %>%
mutate(total_cites = as.numeric(total_cites),
journal_impact_factor = as.numeric(journal_impact_factor)) %>%
mutate(CATEGORY = nom)
}
table_jcr <- bind_rows(liste_revues_jcr) %>% mutate(full_journal_title = str_to_lower(full_journal_title)) %>% unique()
tab_relecture_articles$revue_ouvrage[
tab_relecture_articles$revue_ouvrage %in% table_jcr$full_journal_title]
tab_relecture_articles %>% inner_join(table_jcr, by = c("revue_ouvrage"="full_journal_title"))
tab_relecture_articles %>% inner_join(table_jcr, by = c("revue_ouvrage"="full_journal_title")) %>%
group_by(CATEGORY) %>%
count()
tab_relecture_articles %>% inner_join(table_jcr, by = c("revue_ouvrage"="full_journal_title")) %>%
group_by(CATEGORY) %>%
count() %>% arrange(desc(n))
library(readr)
liste_revues_jcr <- list()
for(i in list.files("data/revues")) {
nom = str_remove_all(i,".csv")
liste_revues_jcr[[nom]] <- read_csv(file.path("data/revues/",i), skip = 1) %>% tibble() %>%
janitor::clean_names() %>%
select(full_journal_title, total_cites, journal_impact_factor) %>%
mutate(total_cites = as.numeric(total_cites),
journal_impact_factor = as.numeric(journal_impact_factor)) %>%
mutate(CATEGORY = nom)
}
table_jcr <- bind_rows(liste_revues_jcr) %>% mutate(full_journal_title = str_to_lower(full_journal_title)) %>% unique()
tab_relecture_articles$revue_ouvrage[
tab_relecture_articles$revue_ouvrage %in% table_jcr$full_journal_title]
tab_relecture_articles %>% inner_join(table_jcr, by = c("revue_ouvrage"="full_journal_title")) %>%
group_by(CATEGORY) %>%
count() %>% arrange(desc(n))
ANX4$i_1_articles_sctfq
ANX4$i_1_articles_sctfq %>% distinct(Journal)
ANX4$i_1_articles_sctfq %>% pull(Journal) %>% unique
ANX4$i_1_articles_sctfq %>% arrange(Journal) %>% pull(Journal) %>% unique
